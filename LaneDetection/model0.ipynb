{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008f2388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebcc8c3",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0e7ff",
   "metadata": {},
   "source": [
    "your_project/\n",
    "│\n",
    "├── data/\n",
    "│   └── datasets.py    # Contains: class LaneDataset(Dataset): ...\n",
    "│\n",
    "├── models/\n",
    "│   └── unet.py        # Contains: def create_unet_model(): ...\n",
    "│\n",
    "├── train.py           # Your training script (where you write: from data.datasets import LaneDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data.datasets import LaneDataset  # we need to implement this\n",
    "from models.unet import create_unet_model  # function to create the model\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "image_size = (256, 256)\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = LaneDataset('path/to/train', image_size=image_size, augment=True)\n",
    "val_dataset = LaneDataset('path/to/val', image_size=image_size, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation='sigmoid'\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # ... validation code ...\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'lane_detection_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3a6e5",
   "metadata": {},
   "source": [
    "## Datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60cf71-947f-43d0-b272-e5a2cbe5ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LaneDataset(Dataset):\n",
    "    def __init__(self, root, image_size=(256, 256), augment=False):\n",
    "        self.root = root\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "\n",
    "        # Collect all json files in the root\n",
    "        self.annotations = []\n",
    "        for file in os.listdir(root):\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(root, file)) as f:\n",
    "                    for line in f:\n",
    "                        data = json.loads(line)\n",
    "                        self.annotations.append(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.annotations[idx]\n",
    "        image_path = os.path.join(self.root, data['raw_file'])\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Create mask\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "        for lane in data['lanes']:\n",
    "            points = list(zip(lane, data['h_samples']))\n",
    "            points = [(x, y) for x, y in points if x >= 0]\n",
    "            if len(points) < 2:\n",
    "                continue\n",
    "            points = np.array(points, dtype=np.int32)\n",
    "            cv2.polylines(mask, [points], isClosed=False, color=1, thickness=5)\n",
    "\n",
    "        # Resize image and mask\n",
    "        image = cv2.resize(image, self.image_size)\n",
    "        mask = cv2.resize(mask, self.image_size)\n",
    "\n",
    "        # Normalize image\n",
    "        image = image / 255.0\n",
    "        mask = mask / 255.0  # mask will be 0 or 1\n",
    "\n",
    "        # Augmentations (flip, rotate, etc.)\n",
    "        if self.augment:\n",
    "            # Example: horizontal flip\n",
    "            if np.random.rand() < 0.5:\n",
    "                image = np.fliplr(image).copy()\n",
    "                mask = np.fliplr(mask).copy()\n",
    "\n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da11ad26-b9a9-4bc6-b9af-42af28fa113e",
   "metadata": {},
   "source": [
    "## lane_detector.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cff2d6-0d1d-4531-a5b3-3fb2658fc5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.unet import create_unet_model  # or directly use the model definition\n",
    "\n",
    "class LaneDetector:\n",
    "    def __init__(self, model_path, image_size=(256, 256)):\n",
    "        self.image_size = image_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=\"mobilenet_v2\",\n",
    "            encoder_weights=None,  # we are loading our own weights\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "            activation='sigmoid'\n",
    "        )\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def detect(self, image):\n",
    "        # Preprocess\n",
    "        original_size = image.shape[:2]\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, self.image_size)\n",
    "        image = image / 255.0\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float().unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(image)\n",
    "        output = output.squeeze().cpu().numpy()\n",
    "        output = (output > 0.5).astype(np.uint8)\n",
    "        output = cv2.resize(output, (original_size[1], original_size[0]))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab7da8-faae-4988-a032-7428814c5209",
   "metadata": {},
   "source": [
    "## controller.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae9d6e7-41b7-4035-b87e-fd73f1210069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIDController:\n",
    "    def __init__(self, kp, ki, kd):\n",
    "        self.kp = kp\n",
    "        self.ki = ki\n",
    "        self.kd = kd\n",
    "        self.integral = 0\n",
    "        self.prev_error = 0\n",
    "\n",
    "    def compute(self, error, dt):\n",
    "        self.integral += error * dt\n",
    "        derivative = (error - self.prev_error) / dt\n",
    "        output = self.kp * error + self.ki * self.integral + self.kd * derivative\n",
    "        self.prev_error = error\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca62a7b-83b8-4f0a-a892-c9472a1a05d5",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cdf80-cd98-4c68-a8c0-b0e3537f5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from inference.lane_detector import LaneDetector\n",
    "from inference.controller import PIDController\n",
    "\n",
    "# Initialize lane detector and controller\n",
    "detector = LaneDetector('lane_detection_model.pth')\n",
    "pid = PIDController(kp=0.1, ki=0.0, kd=0.0)\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect lanes\n",
    "    mask = detector.detect(frame)\n",
    "\n",
    "    # Find lane points in the mask\n",
    "    # We can use a histogram to find the base of the lane, then use sliding window to extract points.\n",
    "    # Alternatively, we can use Hough transform or just take the non-zero points.\n",
    "\n",
    "    # Simple method: take the bottom half of the mask and find the center of the lane.\n",
    "    height, width = mask.shape\n",
    "    half_height = height // 2\n",
    "    bottom_half = mask[half_height:, :]\n",
    "\n",
    "    # Find the x coordinates of the white pixels\n",
    "    points = np.argwhere(bottom_half > 0)\n",
    "    if len(points) > 0:\n",
    "        # We'll fit a line to these points to get the lane center at the bottom\n",
    "        x = points[:, 1]\n",
    "        y = points[:, 0] + half_height  # adjust y coordinate\n",
    "\n",
    "        # Fit a polynomial (linear for simplicity)\n",
    "        coeffs = np.polyfit(y, x, 1)\n",
    "        # Get the x value at the bottom of the image\n",
    "        x_bottom = np.polyval(coeffs, height-1)\n",
    "\n",
    "        # The center of the lane at the bottom is x_bottom\n",
    "        # The center of the image is width/2\n",
    "        error = (width/2 - x_bottom) / width  # normalized error\n",
    "\n",
    "        # Use PID controller to compute steering angle\n",
    "        dt = 1/30  # assuming 30 fps\n",
    "        steering_angle = pid.compute(error, dt)\n",
    "\n",
    "        # Clamp steering angle to [-1, 1] for example\n",
    "        steering_angle = np.clip(steering_angle, -1, 1)\n",
    "\n",
    "        # You can then send this steering_angle to the vehicle's control system.\n",
    "\n",
    "    # Display the mask and frame\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('Mask', mask*255)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
